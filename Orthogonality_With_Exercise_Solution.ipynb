{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Clustering-Crew/UNIV-6080-Notebooks/blob/main/Orthogonality_With_Exercise_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40txSggmnwzQ"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0HQScm5nzRj"
      },
      "source": [
        "# Orthogonality\n",
        "\n",
        "## Finding an orthogonal basis\n",
        "\n",
        "The Gram-Schmidt process is a method for converting a set of basis vectors that are linearly independent but not necessarily orthogonal to an orthogonal set that spans the same subspace.\n",
        "\n",
        "The procedure goes through each basis vector, subtracting off any components in the direction of the previously visited vectors, and then scales the remainder to be unit rank.\n",
        "\n",
        "The [Wikipedia page on Gram-Schmidt](https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process) has a nice animation of it applied in $\\mathbb{R}^3$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90L1cW2Po9Q1"
      },
      "source": [
        "# Source: https://gist.github.com/iizukak/1287876/edad3c337844fac34f7e56ec09f9cb27d4907cc7#gistcomment-2935521\n",
        "def gram_schmidt(A):\n",
        "    \"\"\"Orthogonalize a set of vectors stored as the columns of matrix A.\"\"\"\n",
        "    # Get the number of vectors.\n",
        "    n = A.shape[1]\n",
        "    Q = A.copy()\n",
        "    for j in range(n):\n",
        "        # To orthogonalize the vector in column j with respect to the\n",
        "        # previous vectors, subtract from it its projection onto the\n",
        "        # each of the previous vectors.\n",
        "        for k in range(j):\n",
        "            Q[:, j] -= np.dot(Q[:, k], Q[:, j]) * Q[:, k]\n",
        "        Q[:, j] = Q[:, j] / np.linalg.norm(Q[:, j])\n",
        "    return Q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRsEcC-gxwO7"
      },
      "source": [
        "Let's apply the Gram-Schmidt process to the following basis:\n",
        "\n",
        "$$\n",
        "\\left\\{\n",
        "\\begin{bmatrix} 1\\\\ 1\\\\ 2 \\end{bmatrix},\n",
        "\\begin{bmatrix} 1\\\\ 3\\\\ -1\\\\ \\end{bmatrix},\n",
        "\\begin{bmatrix} 0\\\\ 1\\\\  1\\\\\\end{bmatrix}\n",
        "\\right\\}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-fiPiUWo-Hj",
        "outputId": "8f93b238-c3f4-409e-9566-f65bc130fed1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "A = np.array([[1.0, 1.0, 0.0], [1.0, 3.0, 1.0], [2.0, -1.0, 1.0]])\n",
        "Q = gram_schmidt(A)\n",
        "print(Q)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.40824829  0.20739034 -0.88900089]\n",
            " [ 0.40824829  0.82956136  0.38100038]\n",
            " [ 0.81649658 -0.51847585  0.25400025]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rAU2d0jpSMR"
      },
      "source": [
        "We can see that the columns of Q are orthogonal and are of unit norm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-MPsgf1pcoZ",
        "outputId": "f4660b15-64f3-4add-a611-c8dd72be106c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(np.dot(Q[:, 0], Q[:, 1]))\n",
        "print(np.dot(Q[:, 0], Q[:, 2]))\n",
        "print(np.dot(Q[:, 1], Q[:, 2]))\n",
        "for i in range(Q.shape[1]):\n",
        "  print(np.linalg.norm(Q[:, i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.1102230246251565e-16\n",
            "-3.608224830031759e-16\n",
            "1.3877787807814457e-16\n",
            "1.0\n",
            "0.9999999999999999\n",
            "0.9999999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROD_X1mn1NbF"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "At each step of the Gram-Schmidt process, we project a vector onto each of the previously computed vectors and subtract these components. The projection operator of vector $\\mathbf{v}$ onto vector $\\mathbf{u}$ is defined as\n",
        "\n",
        "$$\\text{proj}_{\\mathbf{u}}(\\mathbf{v}) = \\frac{\\langle \\mathbf{v}, \\mathbf{u} \\rangle}{\\langle \\mathbf{u}, \\mathbf{u} \\rangle} \\mathbf{u}$$\n",
        "\n",
        "We see this implemented on the line\n",
        "\n",
        "```\n",
        "Q[:, j] -= np.dot(Q[:, k], Q[:, j]) * Q[:, k]\n",
        "```\n",
        "\n",
        "above. How come we are missing the denominator, $\\langle\\mathbf{u}, \\mathbf{u} \\rangle = \\|\\mathbf{u}\\|^2$?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "According to the theory, it is true that the norm term is missing in the code implementation. However, there is a normalization step implemented after the inner loops. When we simulate the outer and inner loop we can find that those *k* vectors are already in orthonormal form. Therefore the denominator is safely omitted."
      ],
      "metadata": {
        "id": "RBgFkdnA_83d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "</br>"
      ],
      "metadata": {
        "id": "KhVOYws1CMao"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-HwLlyrvLLz"
      },
      "source": [
        "The Gram-Schmidt process is simple, but numerically unstable and therefore not recommended in practice. Fortunately NumPy provides a more powerful method, `numpy.linalg.qr` which will compute an orthonormal basis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUYkxcRBvMqh",
        "outputId": "7b6d0125-15fc-469d-fc36-c392517fae22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Qnew, _ = np.linalg.qr(A)\n",
        "print(Qnew)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.40824829 -0.20739034 -0.88900089]\n",
            " [-0.40824829 -0.82956136  0.38100038]\n",
            " [-0.81649658  0.51847585  0.25400025]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25ZCYzNYvRFJ"
      },
      "source": [
        "Comparing the result from both approaches, we can see that the orthonormal basis is not unique."
      ]
    }
  ]
}