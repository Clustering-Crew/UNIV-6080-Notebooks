{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Clustering-Crew/UNIV-6080-Notebooks/blob/main/AnalyticGeometry_With_Exercise_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR1jKOx4JVys"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogUJXZqJJLc3"
      },
      "source": [
        "# Analytic Geometry\n",
        "\n",
        "We've already seen multiple views of vectors:\n",
        "\n",
        "* as an array of numbers (a computer science “data structure” view)\n",
        "* as an arrow with a direction and magnitude (a physics view); and\n",
        "* as an object that obeys addition and scaling (a mathematics view)\n",
        "\n",
        "We're going to take a slightly more abstract take on the physics view and add some geometric interpretation and intuition to vectors, vector spaces, and linear mappings. This will yield some useful tools for machine learning topics such as regression, matrix decomposition, and dimensionality reduction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVcDz2n8JR9P"
      },
      "source": [
        "## Norms\n",
        "\n",
        "Taking the square root of an inner product of a vector an itself gives a scalar $\\mathbf{x}^T \\mathbf{x}$ which is known as the Euclidean *norm*. It is a measure of the length of the vector $x$ and is written $||\\mathbf{x}||_2$. It is equivalent to taking the square root of the sum of the squares of the elements of the vector.\n",
        "\n",
        "Let's look at a few different ways to compute the squared Euclidean norm. We're employing the `%%time` cell magic to time execution of a cell. For more control over the measurement (e.g. using repeated loops) you can use `%%timeit`. For more information on profiling and timing code, check out [Jake VanderPlas' chapter on the subject](https://jakevdp.github.io/PythonDataScienceHandbook/01.07-timing-and-profiling.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7gy24gfKAup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c649840-462a-4b4c-c93c-c101d8aa5bb5"
      },
      "source": [
        "x = np.array([1, 2, 3])\n",
        "print(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVN8GKmBNRC_"
      },
      "source": [
        "Explicitly implementing the dot product ourselves:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc-14sIfL9x2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f62c5f6-de9e-4af3-95e7-1b8e1052e4dc"
      },
      "source": [
        "%%time\n",
        "np.sqrt(np.sum(x * x))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 135 µs, sys: 0 ns, total: 135 µs\n",
            "Wall time: 139 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(3.7416573867739413)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os8ccL3LNYkv"
      },
      "source": [
        "Making use of `numpy.dot`, which looks a bit more like the algebraic expression:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PakFPv2KOxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0bec047-1e24-4bb4-a8aa-9b1a0a941098"
      },
      "source": [
        "%%time\n",
        "np.sqrt(np.dot(x.T, x))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 105 µs, sys: 11 µs, total: 116 µs\n",
            "Wall time: 87.5 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(3.7416573867739413)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYbxsmYyNkYt"
      },
      "source": [
        "Note that we didn't actually need the transpose&mdash; NumPy automatically does dot product with two vector inputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOqzNpHNK9rn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4c2ce6-3229-4dee-cd5a-d71a75946d74"
      },
      "source": [
        "%%time\n",
        "np.sqrt(np.dot(x, x))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 68 µs, sys: 4 µs, total: 72 µs\n",
            "Wall time: 64.4 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(3.7416573867739413)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVE4QrP-OF1E"
      },
      "source": [
        "Finally, we use a more powerful function for computing general norms:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGlvyoqSLCN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b0580e-377f-43a4-d117-1c12f3552280"
      },
      "source": [
        "%%time\n",
        "np.linalg.norm(x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 389 µs, sys: 40 µs, total: 429 µs\n",
            "Wall time: 434 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(3.7416573867739413)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SVW1ZFEO_vt"
      },
      "source": [
        "If you're feeling really geeky, you can even call raw BLAS functions directly from SciPy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNjsi6u1Ldm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5fb10f-d327-4967-b82a-885b6a2463c1"
      },
      "source": [
        "import scipy.linalg\n",
        "%time nrm2, = scipy.linalg.get_blas_funcs(('nrm2',), (x,))\n",
        "print(nrm2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 38 µs, sys: 4 µs, total: 42 µs\n",
            "Wall time: 44.8 µs\n",
            "<fortran function dnrm2>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od-74VE0Po6E"
      },
      "source": [
        "What is the difference between `numpy.linalg` and `scipy.linalg`? Well, according to the [SciPy docs](https://docs.scipy.org/doc/scipy/reference/tutorial/linalg.html):\n",
        "\n",
        "> A scipy.linalg contains all the functions that are in numpy.linalg. Additionally, scipy.linalg also has some other advanced functions that are not in numpy.linalg. Another advantage of using scipy.linalg over numpy.linalg is that it is always compiled with BLAS/LAPACK support, while for NumPy this is optional. Therefore, the SciPy version might be faster depending on how NumPy was installed.\n",
        "\n",
        "It is recommended therefore to use `scipy.linalg` instead of `numpy.linalg` unless you don't want to add `scipy` as a dependency to your `numpy` program."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7b51YjDO1NI"
      },
      "source": [
        "### Manhattan ($\\ell_1$) norm\n",
        "\n",
        "The $\\ell_1$ norm for $\\mathbf{x} \\in \\mathbb{R}^n$, $||x||_1 = \\sum_{i=1}^n |x_i|$ is frequently encountered in machine learning. You can compute it similarly to the above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReAsYS_rQc5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89a24c4-a7d0-44a5-9846-d50ed3dec9c2"
      },
      "source": [
        "np.linalg.norm(x, 1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(6.0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWRwfe-5Rz8W"
      },
      "source": [
        "NumPy provides the `numpy.isclose` and `numpy.allclose` functions to test  array-like objects for equality up to desired tolerance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zTvqCV6RJIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c595090-237c-45c9-a64f-b2aa51e89e49"
      },
      "source": [
        "np.allclose(np.linalg.norm(x, 1), np.sum(np.abs(x)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKsKExlMRddR"
      },
      "source": [
        "## Tests for symmetry and positive definiteness\n",
        "\n",
        "Since symmetric, positive definite matrices play an important role in machine learning, it is important to be able to test for these properties.\n",
        "\n",
        "Let's take the matrices from Example 3.4:\n",
        "\n",
        "$$\\mathbf{A}_1 =\n",
        "\\begin{bmatrix} 9 & 6\\\\ 6 & 5\\\\\\end{bmatrix}\n",
        "\\mathbf{A}_2 =\n",
        "\\begin{bmatrix} 9 & 6\\\\ 6 & 3\\\\\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC5AeESpYvbx"
      },
      "source": [
        "A1 = np.array([[9, 6], [6, 5]], dtype='float')\n",
        "A2 = np.array([[9, 6], [6, 3]], dtype='float')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZk7sUW8VNcX"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Before unfolding these blocks, why don't you see if you can write a function to test whether a matrix is symmetric?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise solution\n",
        "def symm_check(matrix: np.array) -> bool:\n",
        "    \"\"\" Function that checks if the given matrix is symmetrical \"\"\"\n",
        "\n",
        "    has_checked = []\n",
        "    for i in range(matrix.shape[0]):\n",
        "        for j in range(matrix.shape[0]):\n",
        "\n",
        "            if i == j or matrix[i][j] in has_checked:\n",
        "                pass\n",
        "            else:\n",
        "                if matrix[i][j] != matrix[j][i]: return False\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "0HDA4YUCqbHV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_matrix_asym = np.array([[1, 4, 5], [5, 12, 23], [2, 5, 8]], dtype='float') # Test case for asymmetric matrix\n",
        "test_matrix_sym = np.array([[4, 5, 3, 6], [5, 8, 9, 1], [3, 9, 13, 2], [6, 1, 2, 16]], dtype='float') # Test case for symmetric matrix\n",
        "\n",
        "%time is_symm = symm_check(test_matrix_sym)\n",
        "\n",
        "print(is_symm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vWsZbAHsKS8",
        "outputId": "aa29caaf-d3ef-48b7-d070-c7262cf8d35e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16 µs, sys: 1e+03 ns, total: 17 µs\n",
            "Wall time: 18.4 µs\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgcjvcIESpVg"
      },
      "source": [
        "#@title\n",
        "from numpy import diag_indices_from, empty_like, finfo, sqrt, asanyarray\n",
        "from numpy.linalg import LinAlgError, cholesky"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34DsXsEKU6jm"
      },
      "source": [
        "#@title\n",
        "# Source: https://numpy-sugar.readthedocs.io/en/stable/_modules/numpy_sugar/linalg/property.html#check_symmetry\n",
        "def check_symmetry(A):\n",
        "    \"\"\"Check if ``A`` is a symmetric matrix.\n",
        "\n",
        "    Args:\n",
        "        A (array_like): Matrix.\n",
        "\n",
        "    Returns:\n",
        "        bool: ``True`` if ``A`` is symmetric; ``False`` otherwise.\n",
        "    \"\"\"\n",
        "    A = asanyarray(A)\n",
        "    if A.ndim != 2:\n",
        "        raise ValueError(\"Checks symmetry only for bi-dimensional arrays.\")\n",
        "\n",
        "    if A.shape[0] != A.shape[1]:\n",
        "        return False\n",
        "\n",
        "    return abs(A - A.T).max() < sqrt(finfo(float).eps)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time check_symmetry(A1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMDyiMwfoaO4",
        "outputId": "a7828bc4-f21f-40de-ba0c-97c555779a24"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 60 µs, sys: 7 µs, total: 67 µs\n",
            "Wall time: 68.7 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.True_"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-WiclL7VAkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da4f5ce-3fda-403f-ed22-8a3bca78ba1b"
      },
      "source": [
        "print(check_symmetry(A1))\n",
        "print(check_symmetry(A2))\n",
        "print(check_symmetry([[1, 2], [3, 4]]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhfg16k4V9y_"
      },
      "source": [
        "With positive definiteness, it's a little more nuanced. An efficient way to test this is to use the NumPy implementation for a particular kind of matrix decomposition called the Cholesky decomposition. We'll explore it in detail in the next unit, so for now let's just treat it like a black box. `numpy.cholesky` will through a `LinAlgError` if its argument is not positive definite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnMRXg5vWx-t"
      },
      "source": [
        "# Source: https://numpy-sugar.readthedocs.io/en/stable/_modules/numpy_sugar/linalg/property.html#check_definite_positiveness\n",
        "def check_definite_positiveness(A):\n",
        "    \"\"\"Check if ``A`` is a definite positive matrix.\n",
        "\n",
        "    Args:\n",
        "        A (array_like): Matrix.\n",
        "\n",
        "    Returns:\n",
        "        bool: ``True`` if ``A`` is definite positive; ``False`` otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        cholesky(A)\n",
        "    except LinAlgError:\n",
        "        return False\n",
        "    return True"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUUpLsjgW16n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a8fd18-199e-4871-b343-981b3b305175"
      },
      "source": [
        "print(check_definite_positiveness(A1))\n",
        "print(check_definite_positiveness(A2))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVeu0s6TXh9K"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Before unfolding the next block, see if you can modify the function above to test for positive semidefiniteness. This is tricky, so don't worry too much if you're stumped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEwTMQfbX_3I"
      },
      "source": [
        "#@title\n",
        "# Source: https://numpy-sugar.readthedocs.io/en/stable/_modules/numpy_sugar/linalg/property.html#check_semidefinite_positiveness\n",
        "def check_semidefinite_positiveness(A):\n",
        "    \"\"\"Check if ``A`` is a positive semi-definite matrix.\n",
        "\n",
        "    Args:\n",
        "        A (array_like): Matrix.\n",
        "\n",
        "    Returns:\n",
        "        bool: ``True`` if ``A`` is positive semidefinite; ``False`` otherwise.\n",
        "    \"\"\"\n",
        "    B = empty_like(A)\n",
        "    B[:] = A\n",
        "    B[diag_indices_from(B)] += sqrt(finfo(float).eps)\n",
        "    try:\n",
        "        cholesky(B)\n",
        "    except LinAlgError:\n",
        "        return False\n",
        "    return True"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8xFllnmYTdM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af816c8c-8ab9-4e50-85e0-e1c1a8581d70"
      },
      "source": [
        "print(check_semidefinite_positiveness(A1))\n",
        "print(check_semidefinite_positiveness(A2))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0bf8jygaDu5"
      },
      "source": [
        "## Orthogonality\n",
        "\n",
        "Let's consider the two vectors in Example 3.7, $\\mathbf{x} = [1, 1]^{\\top}$, $\\mathbf{y} = [-1, 1]^{\\top} \\in \\mathbb{R}^2$.\n",
        "\n",
        "Using the dot product as the inner product yields $\\mathbf{x} \\perp \\mathbf{y}$:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkgxp3JzauTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4184784-1e4c-4f6b-b6f8-ff529a44eccc"
      },
      "source": [
        "x = np.array([1, 1])\n",
        "y = np.array([-1, 1])\n",
        "\n",
        "np.dot(x, y)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPRE5wzTpmOM"
      },
      "source": [
        "However, if we choose the inner product\n",
        "\n",
        "$$\n",
        "\\langle \\mathbf{x} , \\mathbf{y} \\rangle = \\mathbf{x}^{\\top}\n",
        "\\begin{bmatrix}\n",
        "2 & 0\\\\\n",
        "0 & 1\\\\\n",
        "\\end{bmatrix}\n",
        "\\mathbf{y},\n",
        "$$\n",
        "\n",
        "we get that the cosine of the angle $\\omega$ between $\\mathbf{x}$ and $\\mathbf{y}$ given by\n",
        "\n",
        "$$\n",
        "\\cos \\omega = \\frac{\\langle \\mathbf{x} , \\mathbf{y} \\rangle}{\\|\\mathbf{x}\\|\\|\\mathbf{y}\\|}\n",
        "$$\n",
        "\n",
        "is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed2gfOApqLn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a18aa59a-72de-415b-fc72-f1b22ecc70c6"
      },
      "source": [
        "A = np.array([[2, 0], [0, 1]])\n",
        "\n",
        "# define our inner product\n",
        "def innerprod(x, y, A):\n",
        "    return x.dot(A).dot(y)\n",
        "\n",
        "# norm is based on our new inner product\n",
        "def norm(x, A):\n",
        "    return np.sqrt(innerprod(x, x, A))\n",
        "\n",
        "cos_omega = innerprod(x, y, A) / (norm(x, A) * norm(y, A))\n",
        "print(cos_omega)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.33333333333333337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nOE0Em6wACa"
      },
      "source": [
        "To get $\\omega$ we take the triginometric inverse:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHtE9-6rqwZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57d7ec4-9b01-47d2-a905-625a81a60303"
      },
      "source": [
        "omega = np.arccos(cos_omega)\n",
        "print(omega)  # in radians\n",
        "print(np.rad2deg(omega))  # in degrees"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9106332362490186\n",
            "109.47122063449069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3r_pYr0ra_I"
      },
      "source": [
        "So we see that vectors that are orthogonal with respect to one inner product are not necessarily orthogonal to a different inner product."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQQK6o8zyOsU"
      },
      "source": [
        "### Orthogonal matrix\n",
        "\n",
        "A square matrix is orthogonal only if its columns are orthonomal.\n",
        "\n",
        "Let's consider the matrix\n",
        "\n",
        "$$\\mathbf{A} =\n",
        "\\begin{bmatrix} \\cos(0.5) & -\\sin(0.5)\\\\ \\sin(0.5) & \\cos(0.5) \\\\\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz2jTjUbyZLN"
      },
      "source": [
        "A = np.array([[np.cos(0.5), -np.sin(0.5)], [np.sin(0.5), np.cos(0.5)]])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s8_pOLTziGL"
      },
      "source": [
        "First, we'll check if its columns are orthogonal and unit norm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mMfOCboy3G2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77bc281-8f99-4bce-af1c-620ebaacbdf6"
      },
      "source": [
        "print(np.dot(A[:, 0], A[:, 1]))\n",
        "print(np.linalg.norm(A[:, 0]))\n",
        "print(np.linalg.norm(A[:, 1]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "1.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNSUx9PVzhhg"
      },
      "source": [
        "For an orthogonal matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$, $\\mathbf{A}\\mathbf{A}^{\\top} = \\mathbf{I}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpT5J9b70QNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b92b66-b4ff-4235-f360-620721b054fd"
      },
      "source": [
        "np.allclose(np.dot(A, A.T), np.eye(2))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD4UOyN80n3I"
      },
      "source": [
        "The above property also implies that $\\mathbf{A}^{-1} = \\mathbf{A}^{\\top}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htNi0lWp2MSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9391e75-a8ef-46b3-a6ce-a7b7bc772052"
      },
      "source": [
        "np.allclose(A.T, np.linalg.inv(A))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyuX9MkE3Gbz"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "We saw that the columns of an orthogonal matrix are an orthonomal. That is, each column is length one, and mutually perpendicular. What can we say about the rows of an orthogonal basis? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer\n",
        "\n",
        "(Considering the question is about rows of an orthogonal matrix)\n",
        "\n",
        "Since the transpose of an orthogonal matrix is also orthogonal, it can be inferred that each row of an orthogonal matrix has unit length and are mutually perpendicular (orthonormal).\n",
        "\n",
        "Supporting equation: A^TA = I = AA^T\n"
      ],
      "metadata": {
        "id": "h0nVn6j1DKUG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uuc3ZwZfo2_9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}